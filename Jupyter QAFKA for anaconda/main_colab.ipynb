{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYZhxqCWZnFV"
   },
   "source": [
    "#**QAFKA (Quantitative Analysis of Flourescent Kinetics Algorithm)**\n",
    "##**Welcome to QAFKA jupyter notebook**\n",
    "**Disclaimer:**\n",
    "\n",
    "This notebook is based on the following paper: Automated analysis of fluorescence kinetics in single-molecule localization microscopy data reveals protein stoichiometry. [link to paper](https://pubs.acs.org/doi/10.1021/acs.jpcb.1c01130)\n",
    "\n",
    "And source code found in: https://github.com/alonsaguy/QAFKA\n",
    "\n",
    "Please also cite the original paper when using or developing this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL9DXtPkaIob"
   },
   "source": [
    "##**Initialize Colab Session**\n",
    "###**Mount your Google Drive**\n",
    "To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
    "\n",
    "Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive.\n",
    "\n",
    "Once this is done, your data are available in the *Files* tab on the top left of notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hunRW-4RZgn-",
    "outputId": "68a35007-dc43-4cca-fc29-7bec64399c4a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14272/1135340042.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#mounts user's Google Drive to Google Colab.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#@markdown ##Run this cell to connect your Google Drive to Colab\n",
    "\n",
    "#@markdown * Click on the URL. \n",
    "\n",
    "#@markdown * Sign in your Google Account. \n",
    "\n",
    "#@markdown * Copy the authorization code. \n",
    "\n",
    "#@markdown * Enter the authorization code. \n",
    "\n",
    "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\". \n",
    "\n",
    "#mounts user's Google Drive to Google Colab.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_uQ5ja9aeiI"
   },
   "source": [
    "##**Intall QAFKA and dependencies**\n",
    "In the next block we will import the relevant packages for QAFKA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVj2XPzxamX4",
    "outputId": "82541cfb-67d1-4234-cd0b-b3e5506994bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\anaconda\\lib\\site-packages (1.10.0)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: ipympl in d:\\anaconda\\lib\\site-packages (0.8.7)\n",
      "Requirement already satisfied: pillow in d:\\anaconda\\lib\\site-packages (from ipympl) (8.4.0)\n",
      "Requirement already satisfied: traitlets<6 in d:\\anaconda\\lib\\site-packages (from ipympl) (5.1.0)\n",
      "Requirement already satisfied: ipython<9 in d:\\anaconda\\lib\\site-packages (from ipympl) (7.29.0)\n",
      "Requirement already satisfied: ipywidgets<8,>=7.6.0 in d:\\anaconda\\lib\\site-packages (from ipympl) (7.6.5)\n",
      "Requirement already satisfied: matplotlib<4,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from ipympl) (3.4.3)\n",
      "Requirement already satisfied: ipython-genutils in d:\\anaconda\\lib\\site-packages (from ipympl) (0.2.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from ipympl) (1.20.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (3.0.20)\n",
      "Requirement already satisfied: pygments in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (2.10.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (0.18.0)\n",
      "Requirement already satisfied: backcall in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (0.1.2)\n",
      "Requirement already satisfied: pickleshare in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (0.7.5)\n",
      "Requirement already satisfied: decorator in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\anaconda\\lib\\site-packages (from ipython<9->ipympl) (58.0.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in d:\\anaconda\\lib\\site-packages (from ipywidgets<8,>=7.6.0->ipympl) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in d:\\anaconda\\lib\\site-packages (from ipywidgets<8,>=7.6.0->ipympl) (6.4.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in d:\\anaconda\\lib\\site-packages (from ipywidgets<8,>=7.6.0->ipympl) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in d:\\anaconda\\lib\\site-packages (from ipywidgets<8,>=7.6.0->ipympl) (5.1.3)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (6.1.12)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in d:\\anaconda\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (1.4.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\anaconda\\lib\\site-packages (from jedi>=0.16->ipython<9->ipympl) (0.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in d:\\anaconda\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (22.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\anaconda\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in d:\\anaconda\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (4.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in d:\\anaconda\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8,>=7.6.0->ipympl) (228)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib<4,>=2.0.0->ipympl) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib<4,>=2.0.0->ipympl) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib<4,>=2.0.0->ipympl) (0.10.0)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib<4,>=2.0.0->ipympl) (1.16.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in d:\\anaconda\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in d:\\anaconda\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in d:\\anaconda\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8,>=7.6.0->ipympl) (21.2.0)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<9->ipympl) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in d:\\anaconda\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (6.4.5)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in d:\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (1.8.0)\n",
      "Requirement already satisfied: nbconvert in d:\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (6.1.0)\n",
      "Requirement already satisfied: prometheus-client in d:\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.11.0)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (2.11.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in d:\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.9.4)\n",
      "Requirement already satisfied: argon2-cffi in d:\\anaconda\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (20.1.0)\n",
      "Requirement already satisfied: pywinpty>=0.5 in d:\\anaconda\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in d:\\anaconda\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (1.14.6)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (1.1.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in d:\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.5.3)\n",
      "Requirement already satisfied: bleach in d:\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (4.0.0)\n",
      "Requirement already satisfied: defusedxml in d:\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.7.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in d:\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.3)\n",
      "Requirement already satisfied: testpath in d:\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in d:\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in d:\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (1.4.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in d:\\anaconda\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.1.2)\n",
      "Requirement already satisfied: async-generator in d:\\anaconda\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in d:\\anaconda\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (1.5.1)\n",
      "Requirement already satisfied: webencodings in d:\\anaconda\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (0.5.1)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8,>=7.6.0->ipympl) (21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install ipympl\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from scipy.stats import geom, nbinom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "def project01(img):\n",
    "    return (img - img.min()) / (img.max() - img.min())\n",
    "\n",
    "def clean_bg_noise(data, patch_length):\n",
    "    [N, H, W] = data.shape\n",
    "    clean_data = np.zeros_like(data)\n",
    "    half_size = int(np.floor(patch_length / 2))\n",
    "    for t in tqdm(range(N)):\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                start = np.max([0, t-5])\n",
    "                end = np.min([N-1, 5])\n",
    "                up = np.min([H - 1, i + half_size])\n",
    "                down = np.max([0, i - half_size])\n",
    "                right = np.min([W - 1, j + half_size])\n",
    "                left = np.max([0, j - half_size])\n",
    "                clean_data[t, i, j] = data[t, i, j] - np.mean(data[start:end, down:up, left:right])\n",
    "    print(\"-I- Background noise was filtered\")\n",
    "    return clean_data\n",
    "\n",
    "def segment(data, threshold, window_size):\n",
    "    ref_mean = np.mean(data)\n",
    "    ref_std = np.std(data)\n",
    "\n",
    "    for i in tqdm(range(data.shape[0] - window_size)):\n",
    "        curr_mean = np.mean(data[i:i + window_size])\n",
    "        curr_std = np.std(data[i:i + window_size])\n",
    "\n",
    "        if ((np.abs(curr_mean - ref_mean) / ref_mean + np.abs(curr_std - ref_std) / ref_std) < threshold):\n",
    "            print(\"-I- Found segmentation in frame:\", i)\n",
    "            return i\n",
    "\n",
    "    print(\"Error: could not segment, choosing frame 0 as segmentation frame\")\n",
    "    return 0\n",
    "\n",
    "def calc_threshold(raw_data, max_data):\n",
    "    \"\"\"\n",
    "        Calculating a \"good\" threshold fot peak detection\n",
    "        :param raw_data: Tensor [image_size] of one experiment\n",
    "        :return: float as the threshold.\n",
    "    \"\"\"\n",
    "    return 3 * np.mean(np.mean(raw_data, axis=1), axis=1), 1.5 * np.mean(np.mean(max_data, axis=1), axis=1) + np.std(max_data)\n",
    "\n",
    "def draw_circle(size, rad):\n",
    "    # size should be odd\n",
    "    circle = np.zeros([size, size], dtype=int)\n",
    "    mid = int((size - 1) / 2)\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            if ((i - mid) ** 2 + (j - mid) ** 2 <= rad ** 2):\n",
    "                circle[i, j] = 1\n",
    "\n",
    "    return circle\n",
    "\n",
    "def gauss2d(xy, offset, amp, x0, y0, sigma):\n",
    "    # Fit patch to gaussian\n",
    "    x, y = xy\n",
    "    return offset + amp * np.exp(-((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "\n",
    "def Normalization(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        Normalizing the data by the statistics of X_train\n",
    "        :return: normalized X_train, X_val, X_test.\n",
    "    \"\"\"\n",
    "    for i in range(X_train.shape[0]):\n",
    "        X_train[i, :] /= np.sum(X_train[i])\n",
    "    for i in range(X_val.shape[0]):\n",
    "        X_val[i, :] /= np.sum(X_val[i])\n",
    "    for i in range(X_test.shape[0]):\n",
    "        X_test[i, :] /= np.sum(X_test[i])\n",
    "\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "    std[np.where(std == 0)] = 1\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_val = (X_val - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "\n",
    "    return torch.FloatTensor(X_train), torch.FloatTensor(X_val), torch.FloatTensor(X_test)\n",
    "\n",
    "def fit(n_blinks_hist):\n",
    "    \"\"\"\n",
    "        Calculates the MLE for the percentage of dimers in an experiment\n",
    "        :param n_blinks_hist: Tensor [numOfBIns] for the n_blinks histogram in an exp.\n",
    "        :param p: Float for the bleaching probability of a cluster\n",
    "        :return: alpha - the dimers percentage in the experiment.\n",
    "    \"\"\"\n",
    "    best_alpha, best_p = -1, -1\n",
    "    max_val = -np.inf\n",
    "    for j in range(200, 500):\n",
    "        p = j / 1000\n",
    "        for i in range(101):\n",
    "            alpha = i / 100\n",
    "            val = 0\n",
    "            for bin in range(1, len(n_blinks_hist) + 1):\n",
    "                a = p * (1 - p) ** (bin - 1)\n",
    "                b = (bin * (p ** 2)) * (1 - p) ** (bin - 1)\n",
    "                val += n_blinks_hist[bin - 1] * np.log((1 - alpha) * a + alpha * b)\n",
    "\n",
    "            if (val > max_val):\n",
    "                max_val = val\n",
    "                best_alpha = alpha\n",
    "                best_p = p\n",
    "\n",
    "    return best_alpha, best_p\n",
    "\n",
    "def plot_n_blinks(n_blinks, bleach_proba):\n",
    "    for i in range(n_blinks.shape[0]):\n",
    "        plt.plot(n_blinks[i] / np.sum(n_blinks[i]), label='{}'.format(i))\n",
    "    x1 = np.arange(geom.ppf(0.0001, bleach_proba), geom.ppf(0.9999, bleach_proba))\n",
    "    x2 = np.arange(nbinom.ppf(0.0001, 2, bleach_proba), nbinom.ppf(0.9999, 2, bleach_proba))\n",
    "    plt.plot(x1 - 1, geom.pmf(x1, bleach_proba), label='Monomers only')\n",
    "    plt.plot(x2, nbinom.pmf(x2, 2, bleach_proba), label='Dimers only')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def estimate_by_average(n_blinks_hist, bleach_proba):\n",
    "    total_blinks = np.dot(n_blinks_hist, np.arange(1, 21))\n",
    "    total_clusters = np.sum(n_blinks_hist)\n",
    "    best_alpha = None\n",
    "    best_diff = np.inf\n",
    "    for i in range(101):\n",
    "        alpha = i / 100\n",
    "        # Monomers part * Average monomers blinks + Dimers part * Average dimers blinks\n",
    "        approx = ((1 - alpha) * total_clusters) * ((1 / bleach_proba)) + \\\n",
    "                 (alpha * total_clusters) * ((2 * (1 - bleach_proba) / bleach_proba) + 1)\n",
    "        diff = np.abs(approx - total_blinks)\n",
    "        if (diff < best_diff):\n",
    "            best_diff = diff\n",
    "            best_alpha = alpha\n",
    "\n",
    "    return best_alpha\n",
    "\n",
    "def kmeans(data):\n",
    "    from sklearn.manifold import TSNE\n",
    "    from sklearn.cluster import KMeans\n",
    "    X_embedded = TSNE(n_components=2).fit_transform(data)\n",
    "    nbrs = KMeans(n_clusters=2).fit(data)\n",
    "    pred = nbrs.predict(data)\n",
    "    plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=pred)\n",
    "    plt.show()\n",
    "\n",
    "def plotting(hist, p):\n",
    "    hist /= np.sum(hist)\n",
    "    x1 = np.arange(geom.ppf(0.0001, p), geom.ppf(0.9999, p))\n",
    "    n = 2\n",
    "    x2 = np.arange(nbinom.ppf(0.001, n, p), nbinom.ppf(0.999, n, p))\n",
    "    plt.plot(hist, label='Experiment histogram')\n",
    "    plt.plot(x2 + 1, nbinom.pmf(x2, n, p), label='Dimers histogram')\n",
    "    plt.plot(x1 - 1, geom.pmf(x1, p), label='Monomers histogram')\n",
    "    plt.xticks(np.arange(20), np.arange(1, 21))\n",
    "    plt.xlabel('Number of blinks')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Monomers and dimers Nblinks model')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def CoordiantionsComparison(filename, myCoordination):\n",
    "    data = np.loadtxt(filename, delimiter=' ')\n",
    "    col = data[:, 0] / 40200\n",
    "    row = data[:, 1] / 40270\n",
    "    plt.scatter(row, col)\n",
    "    plt.scatter(myCoordination[:, 0] / 251, myCoordination[:, 1] / 257)\n",
    "    plt.xlabel('x [normalized units]')\n",
    "    plt.ylabel('y [normalized units]')\n",
    "    plt.legend(['Tims localizations', 'My localizations'])\n",
    "    plt.show()\n",
    "\n",
    "def debug_helper(data, emitters_grid, fit, obs, center_x, center_y, fit_quality, patch_length):\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(data)\n",
    "    plt.plot(center_y, center_x, color='r', marker='x')\n",
    "    plt.subplot(222)\n",
    "    plt.imshow(emitters_grid)\n",
    "    plt.subplot(223)\n",
    "    plt.title(\"Quality {}\".format(fit_quality))\n",
    "    plt.imshow(fit.reshape([patch_length, patch_length]))\n",
    "    plt.subplot(224)\n",
    "    plt.title(\"Localization {}, {}\".format(center_x, center_y))\n",
    "    plt.imshow(obs.reshape([patch_length, patch_length]))\n",
    "    plt.show()\n",
    "\n",
    "def MLE(n_blinks_hist, p, d):\n",
    "    \"\"\"\n",
    "        Calculates the MLE for the percentage of dimers in an experiment\n",
    "        :param n_blinks_hist: Tensor [numOfBIns] for the n_blinks histogram in an exp.\n",
    "        :param p: Float for the bleaching probability of a cluster\n",
    "        :return: alpha - the dimers percentage in the experiment.\n",
    "    \"\"\"\n",
    "    best_alpha = -1\n",
    "    max_val = -np.inf\n",
    "\n",
    "    val_vec = np.zeros(100)\n",
    "    hist_vec = np.ones(int(np.sum(n_blinks_hist)))\n",
    "    for i in range(len(n_blinks_hist) - 1):\n",
    "        hist_vec[int(np.sum(n_blinks_hist[:i])):int(np.sum(n_blinks_hist[:i + 1]))] = i + 1\n",
    "\n",
    "    for i in range(101):\n",
    "        alpha = i / 100\n",
    "        val = 0\n",
    "        for n in hist_vec:\n",
    "            if (n > 1):\n",
    "                a = p * (1 - p) ** (n - 1)\n",
    "                b = (d * ((n - 1) * (p ** 2)) * (1 - p) ** (n - 2) + (1 - d) * p * (1 - p) ** (n - 1))\n",
    "            else:\n",
    "                a = p * (1 - p) ** (n - 1)\n",
    "                b = (1 - d) * p * (1 - p) ** (n - 1)\n",
    "\n",
    "            val += np.log((1 - alpha) * a + alpha * b)\n",
    "\n",
    "        if (val > max_val):\n",
    "            max_val = val\n",
    "            best_alpha = alpha\n",
    "        val_vec[i - 1] = val\n",
    "    plt.plot(val_vec)\n",
    "    plt.title(\"Real dimers percentage: {}\".format(best_alpha))\n",
    "    plt.show()\n",
    "    return best_alpha\n",
    "\n",
    "def find_actual_dimers_percentage(m, d):\n",
    "    real_percentage = 1 / (((1 - m) / m + 2) * d - 1)\n",
    "    return real_percentage\n",
    "\n",
    "def debug_entire_exp(Max_Data_Set, coordinates, scale_size):\n",
    "    new_img = np.zeros([scale_size * Max_Data_Set[0].shape[0], scale_size * Max_Data_Set[0].shape[1]])\n",
    "    for i in range(Max_Data_Set[0].shape[0] - 1):\n",
    "        for j in range(Max_Data_Set[0].shape[1] - 1):\n",
    "            new_img[(scale_size * i):(scale_size * (i + 1)), (scale_size * j):(scale_size * (j + 1))] = np.max(\n",
    "                Max_Data_Set[:, i, j])\n",
    "    plt.imshow(new_img)\n",
    "    plt.scatter(coordinates[:, 1], coordinates[:, 0], color='r', marker='x')\n",
    "    plt.show()\n",
    "\n",
    "class Trainer():\n",
    "    \"\"\"\n",
    "    A class abstracting the various tasks of training models.\n",
    "    Provides methods at multiple levels of granularity:\n",
    "    - Multiple epochs (fit)\n",
    "    - Single epoch (train_epoch/test_epoch)\n",
    "    - Single batch (train_batch/test_batch)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, loss_fn, optimizer, device='cpu'):\n",
    "        \"\"\"\n",
    "        Initialize the trainer.\n",
    "        :param model: Instance of the model to train.\n",
    "        :param loss_fn: The loss function to evaluate with.\n",
    "        :param optimizer: The optimizer to train with.\n",
    "        :param device: torch.device to run training on (CPU or GPU).\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        model.to(self.device)\n",
    "\n",
    "    def fit(self, dl_train: DataLoader, dl_test: DataLoader,\n",
    "            num_epochs, early_stopping=50, print_every=1, **kw):\n",
    "        \"\"\"\n",
    "        Trains the model for multiple epochs with a given training set,\n",
    "        and calculates validation loss over a given validation set.\n",
    "        :param dl_train: Dataloader for the training set.\n",
    "        :param dl_test: Dataloader for the test set.\n",
    "        :param num_epochs: Number of epochs to train for.\n",
    "        :param early_stopping: Whether to stop training early if there is no\n",
    "            test loss improvement for this number of epochs.\n",
    "        :param print_every: Print progress every this number of epochs.\n",
    "        :return: Train and test losses per epoch.\n",
    "        \"\"\"\n",
    "        train_loss, val_loss = [], []\n",
    "        best_loss = None\n",
    "        best_model = None\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'--- EPOCH {epoch + 1}/{num_epochs} ---')\n",
    "\n",
    "            loss = self.train_epoch(dl_train, **kw)\n",
    "            train_loss.append(loss)\n",
    "\n",
    "            loss = self.test_epoch(dl_test, **kw)\n",
    "            val_loss.append(loss)\n",
    "\n",
    "            if (epoch == 0):\n",
    "                best_loss = loss\n",
    "            else:\n",
    "                if (loss >= best_loss):\n",
    "                    epochs_without_improvement += 1\n",
    "                    if (epochs_without_improvement > early_stopping):\n",
    "                        print(\"Reached early stopping criterion\")\n",
    "                        self.model.load_state_dict(torch.load('best_model'))\n",
    "                        break\n",
    "                else:\n",
    "                    epochs_without_improvement = 0\n",
    "                    best_loss = loss\n",
    "                    torch.save(self.model.state_dict(), 'best_model')\n",
    "\n",
    "            if epoch % print_every == 0 or epoch == num_epochs - 1:\n",
    "                print(\"Epoch\", epoch + 1, \": Train loss =\", train_loss[-1].item())\n",
    "                print(\"Epoch\", epoch + 1, \": Validation loss =\", val_loss[-1].item())\n",
    "\n",
    "    def train_epoch(self, dl_train: DataLoader, **kw):\n",
    "        \"\"\"\n",
    "        Train once over a training set (single epoch).\n",
    "        :param dl_train: DataLoader for the training set.\n",
    "        :param kw: Keyword args supported by _foreach_batch.\n",
    "        :return: An EpochResult for the epoch.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        for X_train, y_train in dl_train:\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = self.model(X_train)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = self.loss_fn(y_pred.squeeze(), y_train)\n",
    "            total_loss += loss\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            cnt += 1\n",
    "        return total_loss / cnt\n",
    "\n",
    "    def test_epoch(self, dl_test: DataLoader, **kw):\n",
    "        \"\"\"\n",
    "        Evaluate model once over a test set (single epoch).\n",
    "        :param dl_test: DataLoader for the test set.\n",
    "        :param kw: Keyword args supported by _foreach_batch.\n",
    "        :return: An EpochResult for the epoch.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        for X_test, y_test in dl_test:\n",
    "            # Forward pass\n",
    "            y_pred = self.model(X_test)\n",
    "            total_loss += self.loss_fn(y_pred.squeeze(), y_test)\n",
    "            cnt += 1\n",
    "\n",
    "        return total_loss / cnt\n",
    "\n",
    "class ONE_LAYER_NET(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ONE_LAYER_NET, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = [self.input_size] + hidden_size\n",
    "\n",
    "        modules = []\n",
    "        modules.append(torch.nn.Linear(self.hidden_size[0], 1, bias=True))\n",
    "        self.net = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return output\n",
    "\n",
    "class SIMPLE_FC_NET(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SIMPLE_FC_NET, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = [self.input_size] + hidden_size\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        for i in range(len(self.hidden_size) - 1):\n",
    "            modules.append(torch.nn.Linear(self.hidden_size[i], self.hidden_size[i + 1], bias=True))\n",
    "            modules.append(torch.nn.PReLU())\n",
    "\n",
    "        modules.append(torch.nn.Linear(self.hidden_size[-1], 1))\n",
    "\n",
    "        self.net = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return output\n",
    "\n",
    "class CustomNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = [self.input_size] + hidden_size\n",
    "\n",
    "        modules = []\n",
    "\n",
    "        for i in range(len(self.hidden_size) - 1):\n",
    "            modules.append(torch.nn.Linear(self.hidden_size[i], self.hidden_size[i + 1]))\n",
    "            modules.append(torch.nn.PReLU())\n",
    "\n",
    "        modules.append(torch.nn.Linear(self.hidden_size[-1], 1))\n",
    "\n",
    "        self.net = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.net(x)\n",
    "        return output\n",
    "\n",
    "def BiasTrick(X_train, X_val, X_test):\n",
    "    coef = 0.05\n",
    "    ones = torch.ones((X_train.shape[0], 1)).type(torch.FloatTensor) * coef\n",
    "    X_train = torch.cat((ones, X_train.type(torch.FloatTensor)), dim=1)\n",
    "    ones = torch.ones((X_val.shape[0], 1)).type(torch.FloatTensor) * coef\n",
    "    X_val = torch.cat((ones, X_val.type(torch.FloatTensor)), dim=1)\n",
    "    ones = torch.ones((X_test.shape[0], 1)).type(torch.FloatTensor) * coef\n",
    "    X_test = torch.cat((ones, X_test.type(torch.FloatTensor)), dim=1)\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "def CreateDataLoader(X, y, batch_size):\n",
    "    \"\"\"\n",
    "        Creates data loader for X, y pairs\n",
    "        :param X: Tensor [# of observations, numOfBins] for the observations\n",
    "        :param y: Tensor [# of observations] for the predictions\n",
    "        :param batch_size: Int for batch size\n",
    "        :return: data loader for training/ testing routines\n",
    "    \"\"\"\n",
    "    data_loader = torch.utils.data.DataLoader(TensorDataset(X, y), batch_size=batch_size)\n",
    "    return data_loader\n",
    "\n",
    "def CreateMaxDataSet(data, max_size, seg):\n",
    "    # Divide the Data_Set into sum_size datasets summing every frame of data in each segment\n",
    "    max_data = np.zeros([max_size, data.shape[1], data.shape[2]])\n",
    "    divider = int(data.shape[0] / max_size)\n",
    "    n = divider - seg\n",
    "    max_data[0, :, :] = np.max(data[:n, :, :], axis=0)\n",
    "    n = divider\n",
    "    for i in range(1, max_size):\n",
    "        max_data[i, :, :] = np.max(data[((i - 1) * n):(i * n), :, :], axis=0)\n",
    "    return max_data\n",
    "\n",
    "def LocalizeEmitters(data, sum_threshold, quality_threshold, pixel_length, resolution_nm, emitters_size):\n",
    "    total_frames, max_row, max_col = data.shape\n",
    "    emitters_grid = np.zeros((int(max_row * pixel_length / resolution_nm),\n",
    "                              int(max_col * pixel_length / resolution_nm)), dtype=int)\n",
    "    emitters_coordinates = []\n",
    "    emitters_cnt = 0\n",
    "\n",
    "    patch_length = 9  # Determine the patch we are going to fit to be of size [patch_length x patch length]\n",
    "    xy = np.zeros([2, int(patch_length ** 2)])\n",
    "    for i1 in range(patch_length):\n",
    "        for j1 in range(patch_length):\n",
    "            xy[:, int(i1 * patch_length + j1)] = [i1, j1]\n",
    "\n",
    "    # Create the shape of a circle for the emitters grid\n",
    "    circle = draw_circle(size=int(patch_length * pixel_length / resolution_nm),\n",
    "                         rad=int(emitters_size / resolution_nm))\n",
    "\n",
    "    bad_fit, out_of_bound = 0, 0\n",
    "    for frame in tqdm(range(total_frames)):\n",
    "        img_arr = data[frame, :, :]\n",
    "        threshold = sum_threshold[frame]\n",
    "        if (np.max(img_arr) > threshold):\n",
    "            potential_peaks = peak_local_max(img_arr, min_distance=int(emitters_size / pixel_length), threshold_abs=threshold)\n",
    "            for i in range(potential_peaks.shape[0]):\n",
    "                row, col = potential_peaks[i, 0], potential_peaks[i, 1]\n",
    "\n",
    "                # Handle clusters in case of exceeding image shape\n",
    "                up = int(row + np.floor(patch_length / 2)) + 1\n",
    "                down = int(row - np.floor(patch_length / 2))\n",
    "                left = int(col - np.floor(patch_length / 2))\n",
    "                right = int(col + np.floor(patch_length / 2)) + 1\n",
    "\n",
    "                # Ignore out of bound blinks\n",
    "                if up > max_row or down < 0 or left < 0 or right > max_col:\n",
    "                    out_of_bound += 1\n",
    "                    continue\n",
    "\n",
    "                # Initial guess\n",
    "                x0, y0 = int(np.floor(patch_length / 2)), int(np.floor(patch_length / 2))\n",
    "\n",
    "                # Fit the patch to a gaussian\n",
    "                zobs = (img_arr[down:up, left:right]).reshape(1, -1).squeeze()\n",
    "\n",
    "                guess = [np.median(img_arr), np.max(img_arr) - np.min(img_arr), x0, y0, 1]\n",
    "                try:\n",
    "                    pred_params, uncert_cov = opt.curve_fit(gauss2d, xy, zobs, p0=guess)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                fit = gauss2d(xy, *pred_params)\n",
    "\n",
    "                # If the peak is higher than threshold proceed\n",
    "                curr_row = int(np.round(down + pred_params[3]))\n",
    "                curr_col = int(np.round(left + pred_params[2]))\n",
    "                if (curr_col >= max_col or curr_col < 0 or curr_row >= max_row or curr_row < 0):\n",
    "                    out_of_bound += 1\n",
    "                    continue\n",
    "\n",
    "                # Handle same coordinate repetition\n",
    "                y = down + pred_params[3]\n",
    "                x = left + pred_params[2]\n",
    "                center_y = int(np.round(y * pixel_length / resolution_nm))\n",
    "                center_x = int(np.round(x * pixel_length / resolution_nm))\n",
    "\n",
    "                # Calculate RMS\n",
    "                zobs = project01(zobs)\n",
    "                fit = project01(fit)\n",
    "                fit_quality = 1 - np.sqrt(np.mean((zobs - fit) ** 2))\n",
    "\n",
    "                # If the fit quality is higher than Value > take the mean value as a new cluster's coordinates\n",
    "                # Ignore fitted gaussian with sigma higher than 1 or lower than 0.3\n",
    "                # if (fit_quality > quality_threshold and pred_params[4] < 1 and pred_params[4] > 0.3):\n",
    "                if (fit_quality > quality_threshold):\n",
    "                    # If the current pixel in the grid is already tagged for one of the emitters\n",
    "                    if (emitters_grid[center_y, center_x] > 0):\n",
    "                        continue\n",
    "\n",
    "                    mid = int((patch_length * pixel_length / resolution_nm) / 2)\n",
    "                    # If the emitter is located outside the image boundaries ignore\n",
    "                    if (center_y - mid < 0 or center_y + mid + 1 >= emitters_grid.shape[0] or\n",
    "                            center_x - mid < 0 or center_x + mid + 1 >= emitters_grid.shape[1]):\n",
    "                        continue\n",
    "\n",
    "                    # Add localization\n",
    "                    emitters_cnt += 1\n",
    "                    # Update emitters_grid\n",
    "                    emitters_grid[(center_y - mid):(center_y - mid + circle.shape[0]),\n",
    "                    (center_x - mid):(center_x - mid + circle.shape[1])] += emitters_cnt * circle\n",
    "                    # Update emitters list\n",
    "                    emitters_coordinates.append([center_y, center_x])\n",
    "                else:\n",
    "                    bad_fit += 1\n",
    "\n",
    "    print(\"Emitter is out of bound:\", out_of_bound)\n",
    "    print(\"Bad fitting grade:\", bad_fit)\n",
    "    print(\"-I- found\", emitters_cnt, \"emitters\")\n",
    "\n",
    "    return np.array(emitters_coordinates)\n",
    "\n",
    "def ExtractTimeTraces(raw_data, emitters_coord, pixel_length, resolution_nm, quality_threshold, threshold,\n",
    "                      emitters_size):\n",
    "    total_frames, max_row, max_col = raw_data.shape\n",
    "    emitters = np.zeros([emitters_coord.shape[0], total_frames])\n",
    "    emitters_size_pix = emitters_size / resolution_nm\n",
    "    patch_length = 5  # Determine the patch we are going to fit to be of size [patch_length x patch length]\n",
    "    xy = np.zeros([2, int(patch_length ** 2)])\n",
    "    for i1 in range(patch_length):\n",
    "        for j1 in range(patch_length):\n",
    "            xy[:, int(i1 * patch_length + j1)] = [i1, j1]\n",
    "\n",
    "    low_intensity, bad_fit, out_of_bound, far_from_emitters = 0, 0, 0, 0\n",
    "    for frame in tqdm(range(total_frames)):\n",
    "        img_arr = raw_data[frame, :, :]\n",
    "        if (np.max(img_arr) > threshold[frame]):\n",
    "            potential_peaks = peak_local_max(img_arr, min_distance=2, threshold_abs=threshold[frame])\n",
    "            for i in range(potential_peaks.shape[0]):\n",
    "                row, col = potential_peaks[i, 0], potential_peaks[i, 1]\n",
    "\n",
    "                # Handle clusters in case of exceeding image shape\n",
    "                up = int(row + np.floor(patch_length / 2)) + 1\n",
    "                down = int(row - np.floor(patch_length / 2))\n",
    "                left = int(col - np.floor(patch_length / 2))\n",
    "                right = int(col + np.floor(patch_length / 2)) + 1\n",
    "\n",
    "                # Ignore out of bound blinks\n",
    "                if up > max_row or down < 0 or left < 0 or right > max_col:\n",
    "                    out_of_bound += 1\n",
    "                    continue\n",
    "\n",
    "                # Initial guess\n",
    "                x0, y0 = int(np.floor(patch_length / 2)), int(np.floor(patch_length / 2))\n",
    "\n",
    "                zobs = (img_arr[down:up, left:right]).reshape(1, -1).squeeze()\n",
    "                guess = [np.median(img_arr), np.max(img_arr) - np.min(img_arr), x0, y0, 1]\n",
    "                try:\n",
    "                    pred_params, uncert_cov = opt.curve_fit(gauss2d, xy, zobs, p0=guess)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                fit = gauss2d(xy, *pred_params)\n",
    "\n",
    "                # Check if localization is in local maximum\n",
    "                if (np.argmax(zobs) != int(np.round(pred_params[2])) * patch_length + int(np.round(pred_params[3]))):\n",
    "                    continue\n",
    "\n",
    "                # If the peak is higher than threshold proceed\n",
    "                curr_row = int(np.round(down + pred_params[3]))\n",
    "                curr_col = int(np.round(left + pred_params[2]))\n",
    "                if (curr_col >= max_col or curr_col < 0 or curr_row >= max_row or curr_row < 0):\n",
    "                    out_of_bound += 1\n",
    "                    continue\n",
    "\n",
    "                # Handle same coordinate repetition\n",
    "                x = left + pred_params[2]\n",
    "                y = down + pred_params[3]\n",
    "                center_y = int(np.round(y * (pixel_length / resolution_nm)))\n",
    "                center_x = int(np.round(x * (pixel_length / resolution_nm)))\n",
    "\n",
    "                dist = np.sqrt(np.sum(([center_y, center_x] - emitters_coord)**2, axis=1))\n",
    "                min_ind = np.argmin(dist)\n",
    "                if (dist[min_ind] > emitters_size_pix):\n",
    "                    far_from_emitters += 1\n",
    "                    continue\n",
    "\n",
    "                if (img_arr[curr_row, curr_col] > threshold[frame]):\n",
    "                    # Calculate RMS\n",
    "                    zobs = project01(zobs)\n",
    "                    fit = project01(fit)\n",
    "                    fit_quality = 1 - np.sqrt(np.mean((zobs - fit) ** 2))\n",
    "\n",
    "                    # If the fit quality is higher than Value > take the mean value as a new cluster's coordinates\n",
    "                    if (fit_quality > quality_threshold):\n",
    "                        # Update emitters list with new time trace\n",
    "                        emitters[min_ind, frame] = pred_params[0] + pred_params[1]  # Offset + Amp of gaussian\n",
    "                    else:\n",
    "                        bad_fit += 1\n",
    "                else:\n",
    "                    low_intensity += 1\n",
    "\n",
    "    print(\"Blink too far from emitters:\", far_from_emitters)\n",
    "    print(\"Emitter is out of bound:\", out_of_bound)\n",
    "    print(\"Bad fitting grade:\", bad_fit)\n",
    "    print(\"Emitters intensity is too low:\", low_intensity)\n",
    "    print(\"-I- updated emitters time traces\")\n",
    "\n",
    "    return emitters\n",
    "\n",
    "def CreateDataSet(file, chop):\n",
    "    \"\"\"\n",
    "        Creates trajectories data set out of experimental data\n",
    "        :param path: String for the path to the data library\n",
    "        :param path: List for start frame and stop frame of the TIFF videos\n",
    "        :return: data set [# of trajectories, trajectories length].\n",
    "    \"\"\"\n",
    "    tiff = Image.open(file)\n",
    "    data = []\n",
    "    for i in tqdm(range(chop[0], chop[1])):\n",
    "        try:\n",
    "            tiff.seek(i)\n",
    "\n",
    "        except Exception as ex:\n",
    "            template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__, ex.args)\n",
    "            print(message)\n",
    "            break\n",
    "        data.append(np.array(tiff))\n",
    "\n",
    "    return np.array(data, dtype=int)\n",
    "\n",
    "def MultiImageDataSet(file_list, chop):\n",
    "    L = len(file_list)\n",
    "    data = []\n",
    "    curr_frame = chop[0]\n",
    "    acc_frames = 0\n",
    "    for l in tqdm(range(L)):\n",
    "        tiff = Image.open(file_list[l])\n",
    "        while (curr_frame < chop[1]):\n",
    "            try:\n",
    "                tiff.seek(curr_frame - acc_frames)\n",
    "\n",
    "            except:\n",
    "                break\n",
    "            data.append(np.array(tiff, dtype='uint8'))\n",
    "            curr_frame += 1\n",
    "        acc_frames = curr_frame\n",
    "    return np.array(data)\n",
    "\n",
    "def feature_extraction(trajectories, threshold, numOfBins):\n",
    "    \"\"\"\n",
    "        Extracting n_blinks features according to the given trajectories\n",
    "        :param trajectories: List of trajectories\n",
    "        :param threshold: Float for minimal threshold for peak detection\n",
    "        :param numOfBins: Int for the range of the n_blinks histogram\n",
    "        :param tau: Int for the tau_c parameter\n",
    "        :return: Tensor [1, numOfBins] for the n_blinks histogram of the experiment.\n",
    "    \"\"\"\n",
    "    L = len(trajectories)\n",
    "    features = np.zeros((L, numOfBins))\n",
    "    n_blinks_per_cluster = []\n",
    "    for i in range(L):\n",
    "        numOfTrajectories, TrajectoryLength = trajectories[i].shape\n",
    "        exp_blink_frames = []\n",
    "        for trajectory in tqdm(range(numOfTrajectories)):\n",
    "            blink_frames = []\n",
    "            n_blinks = 0\n",
    "            frame = 0\n",
    "            while (frame < TrajectoryLength):\n",
    "                if (trajectories[i][trajectory, frame] >= threshold[frame]):\n",
    "                    n_blinks += 1\n",
    "                    start_time = frame + 10\n",
    "                    blink_frames.append(frame)\n",
    "                    while (trajectories[i][trajectory, frame] >= threshold[frame] and frame < start_time):\n",
    "                        frame += 1\n",
    "                        if (frame > TrajectoryLength - 1):\n",
    "                            break\n",
    "                else:\n",
    "                    if (trajectories[i][trajectory, frame] < threshold[frame] / 2):\n",
    "                        while (trajectories[i][trajectory, frame] < threshold[frame]):\n",
    "                            frame += 1\n",
    "                            if (frame > TrajectoryLength - 1):\n",
    "                                break\n",
    "                    else:\n",
    "                        frame += 1\n",
    "\n",
    "            if (n_blinks > 0 and n_blinks < numOfBins):\n",
    "                features[i, n_blinks - 1] += 1\n",
    "                n_blinks_per_cluster.append(n_blinks)\n",
    "            else:\n",
    "                n_blinks_per_cluster.append(0)\n",
    "\n",
    "            exp_blink_frames.append(blink_frames)\n",
    "\n",
    "    np.save('X_test', features)\n",
    "    return features, np.expand_dims(np.array(n_blinks_per_cluster), axis=1), exp_blink_frames\n",
    "\n",
    "def LoadFinalDataSet():\n",
    "    \"\"\"\n",
    "        Loads an existing data set after feature extraction\n",
    "        :return: data set [# of experiments, numOfBins].\n",
    "    \"\"\"\n",
    "    data_set = np.load('X_test.npy')\n",
    "    return data_set\n",
    "\n",
    "def CreateSimulatedDataSet(data_set_size, num_of_molecules, bleach_proba, numOfBins):\n",
    "    \"\"\"\n",
    "        Creates many simulations of features based on ground truth\n",
    "        :param data_set_size: Int for the number of simulations to perform\n",
    "        :param num_of_molecules: Int for the number of molecules to simulate per simulations\n",
    "        :param bleac_proba: Float for the bleaching probability of single cluster\n",
    "        :param numOfBins: Int for the range of the n_blinks histogram\n",
    "        :return: data_set [data_set_size, numOfBins] for the entire simulated data set.\n",
    "    \"\"\"\n",
    "    X = np.zeros([data_set_size, numOfBins])\n",
    "    y = np.zeros(data_set_size)\n",
    "\n",
    "    for i in range(data_set_size):\n",
    "        if (np.random.rand() > 0.4):  # Creating more monomers only experiments\n",
    "            y[i] = 0  # Monomers only\n",
    "        else:\n",
    "            y[i] = np.random.rand()  # Random dimers percentage\n",
    "\n",
    "        MonoList = []\n",
    "        for j in range(int(num_of_molecules - num_of_molecules * y[i])):  # MONOMERS\n",
    "            MonoCnt = 1  # Always start with one blink\n",
    "            while (np.random.rand() > bleach_proba):  # add blinks until bleaches\n",
    "                MonoCnt += 1\n",
    "            MonoList.append(MonoCnt)\n",
    "        DimersList = []\n",
    "        for j in range(int(num_of_molecules - num_of_molecules * y[i]), num_of_molecules):  # DIMERS\n",
    "            DimersCnt = 2  # Always start with two blinks\n",
    "            while (np.random.rand() > bleach_proba):  # add blinks until bleaches\n",
    "                DimersCnt += 1\n",
    "            while (np.random.rand() > bleach_proba):  # dimers bleach twice\n",
    "                DimersCnt += 1\n",
    "            DimersList.append(DimersCnt)\n",
    "\n",
    "        Nblinks_mono = np.histogram(np.array(MonoList) - 1, bins=numOfBins, range=(0, numOfBins))[0]\n",
    "        Nblinks_dimers = np.histogram(np.array(DimersList) - 1, bins=numOfBins, range=(0, numOfBins))[0]\n",
    "\n",
    "        X[i, :] = Nblinks_mono + Nblinks_dimers\n",
    "\n",
    "    np.save('X', X)\n",
    "    np.save('y', y)\n",
    "    return X, y\n",
    "\n",
    "def LoadSimulatedDataSet_special():\n",
    "    \"\"\"\n",
    "        Loads an existing trajectories list\n",
    "        :return: List of trajectories.\n",
    "    \"\"\"\n",
    "    X = np.load('X_special.npy')\n",
    "    y = np.load('y_special.npy')\n",
    "    return X, y\n",
    "\n",
    "def LoadSimulatedDataSet():\n",
    "    \"\"\"\n",
    "        Loads an existing trajectories list\n",
    "        :return: List of trajectories.\n",
    "    \"\"\"\n",
    "    X = np.load('X.npy')\n",
    "    y = np.load('y.npy')\n",
    "    return X, y\n",
    "\n",
    "def Filter_beads(data):\n",
    "    mean_intensity = np.mean(data)\n",
    "    std_intensity = np.std(data)\n",
    "    bids_loc = np.where(np.mean(data, axis=0) > mean_intensity * 1.1)\n",
    "    data[:, bids_loc[0], bids_loc[1]] = np.random.normal(mean_intensity, std_intensity,\n",
    "                                                         [data.shape[0], len(bids_loc[0])])\n",
    "    return data\n",
    "\n",
    "print(\"Packages installation completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8uZ4D14avIT"
   },
   "source": [
    "##**Parameter Initiallization**\n",
    "Now you should specify some important parameters for your run.\n",
    "\n",
    "**numOfBins** - Specifies the number of bins in the histogram of the number of blinking events (default: 20)\n",
    "\n",
    "**start/end_frame** - Specifies which frames of the experiment you would like to analyze. For example: start_frame = 0 and end_frame=1000 will cause QAFKA to analyze the experiment between the first frame and the 1000th frame.\n",
    "\n",
    "**pixel_length** - Specifies the experiment's pixel size [nm]\n",
    "\n",
    "**scale_size** - Specifies the resolution scaling. For example: scale_size = 3 and pixel_length = 150 [nm] would results in a reconstrcuted image with grid size of 50 [nm].\n",
    "\n",
    "**emitters_size** - Specifies the emitters merging radius for detection. If two clusters would be located within this radius they would be considered as a single cluster.\n",
    "\n",
    "**numOfClusters** - Specifies the number of simulated clusters in each simulated experiment\n",
    "\n",
    "**file_name** - Specifies the name of the TIFF file . For example: 'my_exp.tif'.\n",
    "\n",
    "**file_name2/3** - In case a single experiment is consisted of multiple TIF files, specify here up to 3 different files by chronological order.\n",
    "\n",
    "**qualityThreshold** - Specifies the minimal fitting score for the localization block. (default: 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "l2voT5XZbjA4"
   },
   "outputs": [],
   "source": [
    "numOfBins = 20 #@param {type:\"number\"}\n",
    "start_frame = 0 #@param {type:\"number\"}\n",
    "end_frame = 12000 #@param {type:\"number\"}\n",
    "pixel_length = 80# @param {type:\"number\"}\n",
    "scale_size = 2 #@param {type:\"number\"}\n",
    "merging_radius = 250 #@param {type:\"number\"}\n",
    "file_name = 'D:/Project/MonoDimerClassification/data/CD86-mEos32_PALM_2_1.tif' #@param {type:\"string\"}\n",
    "file_name2 = '' #@param {type:\"string\"}\n",
    "file_name3 = '' #@param {type:\"string\"}\n",
    "qualityThreshold = 0.85 #@param {type:\"number\"}\n",
    "chop = [start_frame, end_frame]\n",
    "if(file_name2 != ''):\n",
    "    if(file_name3 != ''):\n",
    "        file_list = [file_name, file_name2, file_name3]\n",
    "    else:\n",
    "        file_list = [file_name, file_name2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx_ks0pjbmQL"
   },
   "source": [
    "##**Run Configuration**\n",
    "\n",
    "**LoadData** - Determines if we want to load new experimental data (True) or we want to use an already loaded data (False).\n",
    "\n",
    "**MultiTIF** - Change this flag to True case you have specified multiple TIF files as a single experiment.\n",
    "\n",
    "**FilterBeads** - Determines if an additional beads filtration algorithm is needed for the experimental data.\n",
    "\n",
    "**CreateSimulatedData** - Determines if we want to use the same training data as before (True) or we want to create new training set (False).\n",
    "\n",
    "**TrainNet** - Determines if we want to train the neural network (True) or not (False). Usually it takes ~5 minutes to train the network.\n",
    "\n",
    "**preTrainedModel** - Specifies the pre-trained model to load in case we do not want to train the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZAM1Kxp4b2cv"
   },
   "outputs": [],
   "source": [
    "LoadData = True #@param {type:\"boolean\"}\n",
    "MultiTif = False #@param {type:\"boolean\"}\n",
    "FilterBeads = True #@param {type:\"boolean\"}\n",
    "CreateSimulatedData = True #@param {type:\"boolean\"}\n",
    "TrainNet = True #@param {type:\"boolean\"}\n",
    "preTrainedModel = 'model_final_gauss' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KP2_vE5ScBTA"
   },
   "source": [
    "##**Analysis Pipeline**\n",
    "\n",
    "Run this block to analyze the provided tiff stacks and generate number of blinking events histograms per experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "epmmihBBcFoH",
    "outputId": "7ebbbcdb-7369-415a-8f65-f78eb917928f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resolution_nm = pixel_length/scale_size #[nm]\n",
    "\n",
    "if (LoadData):\n",
    "    trajectories, clusterCoordinations = [], []\n",
    "    print(\"**** Analyzing Tiff file ****\")\n",
    "    # Load TIFF files and create data_set\n",
    "    print('-I- Loading tif file')\n",
    "    if(MultiTif):\n",
    "        Data_Set = MultiImageDataSet(file_list, chop)\n",
    "    else:\n",
    "        Data_Set = CreateDataSet(file_name, chop)\n",
    "    if (Data_Set.shape[0] < 2000):\n",
    "        max_size = int((Data_Set.shape[0]) / 500)\n",
    "    else:\n",
    "        max_size = int((Data_Set.shape[0]) / 1000)\n",
    "\n",
    "    if np.all(Data_Set != -1):\n",
    "        # Segment the experiment before and after laser activation\n",
    "        print('-I- Segmenting')\n",
    "        seg = 0 #segment(Data_Set, threshold=0.15, window_size=100)\n",
    "\n",
    "        # Filter beads (if True)\n",
    "        if (FilterBeads):\n",
    "            print('-I- Filtering beads')\n",
    "            Data_Set = Filter_beads(Data_Set)\n",
    "\n",
    "        # Background noise cleaning\n",
    "        # print('-I- Cleaning background noise')\n",
    "        # Data_Set = clean_bg_noise(Data_Set, patch_length=3)\n",
    "\n",
    "        # Clusters localization\n",
    "        print('-I- Localizing emitters')\n",
    "        Max_Data_Set = CreateMaxDataSet(Data_Set, max_size, seg)\n",
    "        DataThreshold, MaxThreshold = calc_threshold(Data_Set, Max_Data_Set)\n",
    "        coordinates = LocalizeEmitters(Max_Data_Set, MaxThreshold, qualityThreshold, pixel_length, resolution_nm, merging_radius)\n",
    "\n",
    "        # Create time traces for each cluster\n",
    "        print('-I- Extracting time traces')\n",
    "        timeTraces = ExtractTimeTraces(Data_Set[seg:, :, :], coordinates, pixel_length, resolution_nm, qualityThreshold, DataThreshold, merging_radius)\n",
    "\n",
    "        # Save the time traces and clusters locations of all experiments in a list\n",
    "        trajectories.append(timeTraces)\n",
    "        clusterCoordinations.append(coordinates)\n",
    "\n",
    "        # The coordinations file would be saved as 'coordinated.npy'\n",
    "        np.save('clusterCoordinations', clusterCoordinations)\n",
    "\n",
    "        # Extract the features that would serve as the neural network's input\n",
    "        print('-I- Extracting blinking kinetics features')\n",
    "        X_test, n_blink_per_cluster, exp_blink_frames = feature_extraction(trajectories, DataThreshold, numOfBins)\n",
    "\n",
    "        # Save results\n",
    "        with open(\"blink_frames.csv\", \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(exp_blink_frames)\n",
    "\n",
    "            num_of_blinks_per_cluster = np.concatenate(\n",
    "                [pixel_length * clusterCoordinations[0] / scale_size, n_blink_per_cluster], axis=1)\n",
    "            np.save('num_of_blinks_per_cluster', num_of_blinks_per_cluster)\n",
    "\n",
    "        plt.plot(X_test[0])\n",
    "        plt.show()\n",
    "        print(\"Experimental Data was loaded successfully\")\n",
    "    else:\n",
    "        print(\"Experimental Data was not loaded\")\n",
    "else:\n",
    "    # Load features of an already analyzed experiment\n",
    "    X_test = LoadFinalDataSet()\n",
    "    print(\"Experimental Data was loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPenmn2DcXHm"
   },
   "source": [
    "##**Plot Histograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "Oz2npoGhcXZR",
    "outputId": "1ad2008f-b92d-4268-fa9d-95fae0ca1085"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.bar(np.arange(numOfBins), X_test[i])\n",
    "    plt.xlabel('Number of blinking events')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.xticks(np.arange(numOfBins), np.arange(1, numOfBins + 1))\n",
    "    plt.yticks(np.arange(1, np.max(X_test[i]) + 1, np.max(X_test[i])/10))\n",
    "    plt.title(\"Exp \" + str(i+1) + \" histogram\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjSOy90VcXfm"
   },
   "source": [
    "##**Export to Excel**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVLDlXE7cXlq",
    "outputId": "db6bc5a6-5ae3-482b-ad13-e7f9304d43b2"
   },
   "outputs": [],
   "source": [
    "export_dir = 'D:/Project/MonoDimerClassification/data' #@param {type:\"string\"}\n",
    "\n",
    "np.savetxt(os.path.join(export_dir, \"Exp_histogram.csv\"), X_test[0], delimiter=',')\n",
    "np.savetxt(os.path.join(export_dir, \"Exp_localization.csv\"), num_of_blinks_per_cluster, delimiter=',')\n",
    "\n",
    "print(\"Data export completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_oPWTEFcnH5"
   },
   "source": [
    "##**Visualize Localizations**\n",
    "\n",
    "The next block will plot a max projection image of the last experiment with the localization marked on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "rwIryTjkcwui",
    "outputId": "8d39a5b6-4335-4ec5-937f-e41c54d769be"
   },
   "outputs": [],
   "source": [
    "if(LoadData):\n",
    "    debug_entire_exp(Max_Data_Set, coordinates, scale_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viCcxS4jcxC8"
   },
   "source": [
    "##**Data Simulation Configuration**\n",
    "If you chose to simulate the training data, you would need to specify the following parameters:\n",
    "\n",
    "**numOfClusters** - Specifies the number of simulated clusters in each simulation (relevant only if CreateSimulatedData is set to True).\n",
    "\n",
    "**bleach_proba** - Specifies the bleaching probability [0, 1] of the used fluorophore.\n",
    "\n",
    "**TrainSetSize** - Specifies the number of simulated experiments to be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "cya-fokOc7sY"
   },
   "outputs": [],
   "source": [
    "numOfClusters = 200 #@param {type:\"number\"}\n",
    "bleach_proba = 0.41 #@param {type:\"number\"}\n",
    "TrainSetSize = 10000 #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgHvUdMkc_y6"
   },
   "source": [
    "##**Create Simulated Training Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gO3zWu6NdFi7",
    "outputId": "755e5f6a-69fb-45cc-c63c-d8dc84ceae2a"
   },
   "outputs": [],
   "source": [
    "if(CreateSimulatedData):\n",
    "    [X, y] = CreateSimulatedDataSet(TrainSetSize, numOfClusters, bleach_proba, numOfBins)\n",
    "else:\n",
    "    [X, y] = LoadSimulatedDataSet()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.75)\n",
    "[X_train, X_val, X_test] = Normalization(X_train, X_val, X_test)\n",
    "[X_train, X_val, X_test] = BiasTrick(X_train, X_val, X_test)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_val = torch.FloatTensor(y_val)\n",
    "\n",
    "print(\"-I- Simulated Data was created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AL4R4k7mdGUE"
   },
   "source": [
    "##**Build Model**\n",
    "\n",
    "In the next block we will build the neural network model.\n",
    "\n",
    "**lr** - Specifies the training phase learning rate.\n",
    "\n",
    "**betas** - Specifies the parameters for ADAM optimizer.\n",
    "\n",
    "**batch_size** - Specifies the batch size of the training phase.\n",
    "\n",
    "**epochs** - Specifies the maximal training epoch.\n",
    "\n",
    "**early_stopping** - Specifies the tolerance of the neural network to lack of improvement in the validation loss. For example: early_stopping = 5, would stop the trainig phase if the validation loss did not improve for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rj1HtnQYdQqp"
   },
   "outputs": [],
   "source": [
    "lr = 1e-5 #@param {type:\"number\"}\n",
    "betas = (0.99, 0.999) \n",
    "batch_size = 4 #@param {type:\"number\"}\n",
    "epochs = 1000 #@param {type:\"number\"}\n",
    "early_stopping = np.min((int(epochs/5), 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVLo2infdRNX"
   },
   "source": [
    "##**Training Phase**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0OJ-NejdVa5",
    "outputId": "208467f0-736c-45d4-d0f4-cee650ad0c7b"
   },
   "outputs": [],
   "source": [
    "if(TrainNet):\n",
    "    model = CustomNet(torch.numel(X_train[0]), [128, 128, 128, 128])\n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    dl_train = CreateDataLoader(X_train, y_train, batch_size=batch_size)\n",
    "    dl_val = CreateDataLoader(X_val, y_val, batch_size=1)\n",
    "\n",
    "    # ================= Train Net ================\n",
    "    trainer = Trainer(model, criterion, optimizer)\n",
    "    trainer.fit(dl_train, dl_val, num_epochs=epochs, early_stopping=early_stopping, print_every=1)\n",
    "    torch.save(trainer.model.state_dict(), 'model_final_gauss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysUduqPldV_N"
   },
   "source": [
    "##**Load Pre-trained Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eiu6XAGuda6Y",
    "outputId": "7a02fe05-3600-4efc-f760-8fa772da58dc"
   },
   "outputs": [],
   "source": [
    "model = CustomNet(torch.numel(X_train[0]), [128, 128, 128, 128])\n",
    "model.load_state_dict(torch.load(preTrainedModel))\n",
    "print(\"Pretrained model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T_I8F7wdbQm"
   },
   "source": [
    "##**Testing Phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nH6fvucpdeMm",
    "outputId": "7af22e8a-66f5-4732-b2f9-5637d6b70431"
   },
   "outputs": [],
   "source": [
    "y_val_pred = model(X_val)\n",
    "y_test_pred = model(X_test).squeeze()\n",
    "y_test_pred = torch.max(y_test_pred, torch.zeros(y_test_pred.shape))\n",
    "\n",
    "val_acc = torch.mean(torch.abs(y_val_pred.squeeze() - y_val))\n",
    "print(\"Neural Network Validation MSE:\", 100 * val_acc.item())\n",
    "\n",
    "print(\"Printing dimer percentage per experiment:\")\n",
    "if(y_test_pred.shape == torch.Size([])):\n",
    "    print(\"1: \", 100 * y_test_pred.item())\n",
    "else:\n",
    "    for i in range(y_test_pred.shape[0]):\n",
    "        print(str(i+1)+\": \", 100 * y_test_pred[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW4uD8ELdgF-"
   },
   "source": [
    "##**Detection Efficiency Correction**\n",
    "Please specify the detection efficiency in your experiment. It should be a number in the range [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "WwMcuVm1dlYH"
   },
   "outputs": [],
   "source": [
    "detection_efficiency = 0.78 #@param {type:\"number\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "511x4mzidloI"
   },
   "source": [
    "###**Calculate Final Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obenZhW1dlt0",
    "outputId": "42715b3c-189c-4c66-86e4-a84225b16e05"
   },
   "outputs": [],
   "source": [
    "print(\"Printing corrected dimer percentage per experiment:\")\n",
    "if(y_test_pred.shape == torch.Size([])):\n",
    "    print(\"1: \", np.min([100, 100 * find_actual_dimers_percentage(y_test_pred.item(), detection_efficiency)]))\n",
    "else:\n",
    "    for i in range(y_test_pred.shape[0]):\n",
    "         print(str(i+1)+\": \", np.min([100, 100 * find_actual_dimers_percentage(y_test_pred[i].item(), detection_efficiency)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "zgHvUdMkc_y6",
    "AL4R4k7mdGUE",
    "PVLo2infdRNX",
    "ysUduqPldV_N"
   ],
   "name": "main_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

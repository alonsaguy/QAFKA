{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6_uQ5ja9aeiI",
        "KP2_vE5ScBTA",
        "MPenmn2DcXHm",
        "SjSOy90VcXfm",
        "z_oPWTEFcnH5",
        "zgHvUdMkc_y6",
        "AL4R4k7mdGUE",
        "PVLo2infdRNX",
        "ysUduqPldV_N",
        "2T_I8F7wdbQm",
        "IW4uD8ELdgF-",
        "511x4mzidloI"
      ],
      "authorship_tag": "ABX9TyPdIRcYHHQyR+TcT/AEx8WI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alonsaguy/QAFKA/blob/main/main_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYZhxqCWZnFV"
      },
      "source": [
        "#**QAFKA (Quantitative Analysis of Flourescent Kinetics Algorithm)**\n",
        "##**Welcome to QAFKA jupyter notebook**\n",
        "**Disclaimer:**\n",
        "\n",
        "This notebook is based on the following paper: Automated analysis of fluorescence kinetics in single-molecule localization microscopy data reveals protein stoichiometry. [link to paper](google.com)\n",
        "\n",
        "And source code found in: https://github.com/alonsaguy/QAFKA\n",
        "\n",
        "Please also cite this original paper when using or developing this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL9DXtPkaIob"
      },
      "source": [
        "##**Initialize Colab Session**\n",
        "###**Mount your Google Drive**\n",
        "To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
        "\n",
        "Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive.\n",
        "\n",
        "Once this is done, your data are available in the *Files* tab on the top left of notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hunRW-4RZgn-"
      },
      "source": [
        "#@markdown ##Run this cell to connect your Google Drive to Colab\n",
        "\n",
        "#@markdown * Click on the URL. \n",
        "\n",
        "#@markdown * Sign in your Google Account. \n",
        "\n",
        "#@markdown * Copy the authorization code. \n",
        "\n",
        "#@markdown * Enter the authorization code. \n",
        "\n",
        "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\". \n",
        "\n",
        "#mounts user's Google Drive to Google Colab.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_uQ5ja9aeiI"
      },
      "source": [
        "##**Intall QAFKA and dependencies**\n",
        "In the next block we will import the relevant packages for QAFKA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVj2XPzxamX4"
      },
      "source": [
        "!pip install tiffcapture\n",
        "!pip install torch\n",
        "!pip install ipympl\n",
        "\n",
        "from datasets import *\n",
        "from dataloaders import *\n",
        "from neural_network import *\n",
        "from trainers import *\n",
        "from utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Packages installation completed successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8uZ4D14avIT"
      },
      "source": [
        "##**Parameters Initiallization**\n",
        "Now you should specify some important parameters for your run.\n",
        "\n",
        "**numOfBins** - Specifies the number of bins in the histogram of the number of blinking events (default: 20)\n",
        "\n",
        "**start/end_frame** - Specifies which frames of the experiment you would like to analyze. For example: start_frame = 0 and end_frame=1000 will cause QAFKA to analyze the experiment between the first frame and the 1000th frame.\n",
        "\n",
        "**pixel_length** - Specifies the experiment's pixel size [nm]\n",
        "\n",
        "**scale_size** - Specifies the resolution scaling. For example: scale_size = 3 and pixel_length = 150 [nm] would results in a reconstrcuted image with grid size of 50 [nm].\n",
        "\n",
        "**emitters_size** - Specifies the emitters merging radius for detection. If two clusters would be located within this radius they would be considered as a single cluster.\n",
        "\n",
        "**numOfClusters** - Specifies the number of simulated clusters in each simulated experiment\n",
        "\n",
        "**file_names** - Specifies the names of the TIFF files (at least one experiment is required). For example: 'first_exp.tif'.\n",
        "\n",
        "**qualityThreshold** - Specifies the minimal fitting score for the localization block. (default: 0.85)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2voT5XZbjA4"
      },
      "source": [
        "numOfBins = 20 #@param {type:\"number\"}\n",
        "start_frame = 0 #@param {type:\"number\"}\n",
        "end_frame = 2000 #@param {type:\"number\"}\n",
        "pixel_length = 157# @param {type:\"number\"}\n",
        "scale_size = 3 #@param {type:\"number\"}\n",
        "merging_radius = 50 #@param {type:\"number\"}\n",
        "file_names = 'D:\\Project\\data\\CTLA4\\mEos3.2.tif' #@param {type:\"string\"}\n",
        "qualityThreshold = 0.85 #@param {type:\"number\"}\n",
        "chop = [start_frame, end_frame]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx_ks0pjbmQL"
      },
      "source": [
        "##**Run Configuration**\n",
        "**LoadData** - Determines if we want to load new experimental data (True) or we want to use an already loaded data (False).\n",
        "\n",
        "**FilterBeads** - Determines if an additional beads filtration algorithm is needed for the experimental data.\n",
        "\n",
        "**CreateSimulatedData** - Determines if we want to use the same training data as before (True) or we want to create new training set (False).\n",
        "\n",
        "**TrainNet** - Determines if we want to train the neural network (True) or not (False). Usually it takes ~5 minutes to train the network.\n",
        "\n",
        "**preTrainedModel** - Specifies the pre-trained model to load in case we do not want to train the net."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ZAM1Kxp4b2cv"
      },
      "source": [
        "LoadData = True #@param {type:\"boolean\"}\n",
        "FilterBeads = False #@param {type:\"boolean\"}\n",
        "CreateSimulatedData = True #@param {type:\"boolean\"}\n",
        "TrainNet = True #@param {type:\"boolean\"}\n",
        "preTrainedModel = 'model_final_gauss' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP2_vE5ScBTA"
      },
      "source": [
        "##**Analysis Pipeline**\n",
        "Run this block to analyze the provided tiff stacks and generate number of blinking events histograms per experiment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epmmihBBcFoH"
      },
      "source": [
        "if(chop[1]-chop[0]<2000):\n",
        "    max_size = int((chop[1]-chop[0])/500)\n",
        "else:\n",
        "    max_size = int((chop[1]-chop[0])/1000)\n",
        "    \n",
        "resolution_nm = pixel_length/scale_size #[nm]\n",
        "\n",
        "if(LoadData):\n",
        "    trajectories, clusterCoordinations = [], []\n",
        "    for i, file in enumerate(file_names):\n",
        "        print(\"**** Analyzing Tiff number {} ****\".format(i+1))\n",
        "        # Load TIFF files and create data_set\n",
        "        Data_Set = CreateDataSet(file, chop)\n",
        "        \n",
        "        # Segment the experiment before and after laser activation\n",
        "        seg = segment(Data_Set, threshold=0.15, window_size=100)\n",
        "        \n",
        "        # Filter beads (if True)\n",
        "        if(FilterBeads):\n",
        "            Data_Set = Filter_beads(Data_Set)\n",
        "        \n",
        "        # Background noise cleaning\n",
        "        Data_Set = clean_bg_noise(Data_Set, patch_length=5)\n",
        "        \n",
        "        # Clusters localization\n",
        "        Max_Data_Set = CreateMaxDataSet(Data_Set, max_size, seg)\n",
        "        DataThreshold, MaxThreshold = calc_threshold(Data_Set, Max_Data_Set)\n",
        "        coordinates = LocalizeEmitters(Max_Data_Set, MaxThreshold, qualityThreshold, pixel_length, resolution_nm, merging_radius)\n",
        "        \n",
        "        # Create time traces for each cluster\n",
        "        timeTraces = ExtractTimeTraces(Data_Set[seg:, :, :], coordinates, pixel_length, resolution_nm, qualityThreshold, DataThreshold, merging_radius)\n",
        "        \n",
        "        # Save the time traces and clusters locations of all experiments in a list\n",
        "        trajectories.append(timeTraces)\n",
        "        clusterCoordinations.append(coordinates)\n",
        "        \n",
        "        # The coordinations file would be saved as 'coordinated.npy'\n",
        "    np.save('clusterCoordinations', clusterCoordinations)\n",
        "\n",
        "    # Extract the features that would serve as the neural network's input\n",
        "    X_test = feature_extraction(trajectories, DataThreshold, numOfBins)\n",
        "else:\n",
        "    # Load features of an already analyzed experiment\n",
        "    X_test = LoadFinalDataSet()\n",
        "\n",
        "print(\"Experimental Data was loaded successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPenmn2DcXHm"
      },
      "source": [
        "##**Plot Histograms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz2npoGhcXZR"
      },
      "source": [
        "%matplotlib widget\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    plt.figure()\n",
        "    plt.plot(np.arange(1, numOfBins + 1), X_test[i])\n",
        "    plt.xlabel('Bins')\n",
        "    plt.ylabel('Counts')\n",
        "    plt.xticks(np.arange(1, numOfBins + 1))\n",
        "    plt.title(\"Exp \" + str(i+1) + \" histogram\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjSOy90VcXfm"
      },
      "source": [
        "##**Export to Excel**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVLDlXE7cXlq"
      },
      "source": [
        "for i in range(X_test.shape[0]):\n",
        "    np.savetxt(\"Exp_\"+str(i+1)+\"_histogram.csv\", X_test[i], delimiter=',')\n",
        "    np.savetxt(\"Exp_\"+str(i+1)+\"_localization.csv\", clusterCoordinations[i], delimiter=',')\n",
        "\n",
        "print(\"Data export completed successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_oPWTEFcnH5"
      },
      "source": [
        "##**Visualize Localizations**\n",
        "The next block will plot a max projection image of the last experiment with the localization marked on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwIryTjkcwui"
      },
      "source": [
        "if(LoadData):\n",
        "    debug_entire_exp(Max_Data_Set, coordinates, scale_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viCcxS4jcxC8"
      },
      "source": [
        "##**Data Simulation Configuration**\n",
        "If you chose to simulate the training data, you would need to specify the following parameters:\n",
        "\n",
        "**numOfClusters** - Specifies the number of simulated clusters in each simulation (relevant only if CreateSimulatedData is set to True).\n",
        "\n",
        "**bleach_proba** - Specifies the bleaching probability [0, 1] of the used fluorophore.\n",
        "\n",
        "**TrainSetSize** - Specifies the number of simulated experiments to be created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cya-fokOc7sY"
      },
      "source": [
        "numOfClusters = 200 #@param {type:\"number\"}\n",
        "bleach_proba = 0.41 #@param {type:\"number\"}\n",
        "TrainSetSize = 10000 #@param {type:\"number\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgHvUdMkc_y6"
      },
      "source": [
        "##**Create Simulated Training Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO3zWu6NdFi7"
      },
      "source": [
        "if(CreateSimulatedData):\n",
        "    [X, y] = CreateSimulatedDataSet(TrainSetSize, numOfClusters, bleach_proba, numOfBins)\n",
        "else:\n",
        "    [X, y] = LoadSimulatedDataSet()\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.75)\n",
        "[X_train, X_val, X_test] = Normalization(X_train, X_val, X_test)\n",
        "[X_train, X_val, X_test] = BiasTrick(X_train, X_val, X_test)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "y_val = torch.FloatTensor(y_val)\n",
        "\n",
        "print(\"-I- Simulated Data was created successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL4R4k7mdGUE"
      },
      "source": [
        "##**Build Model**\n",
        "In the next block we will build the neural network model.\n",
        "\n",
        "**lr** - Specifies the training phase learning rate.\n",
        "\n",
        "**betas** - Specifies the parameters for ADAM optimizer.\n",
        "\n",
        "**batch_size** - Specifies the batch size of the training phase.\n",
        "\n",
        "**epochs** - Specifies the maximal training epoch.\n",
        "\n",
        "**early_stopping** - Specifies the tolerance of the neural network to lack of improvement in the validation loss. For example: early_stopping = 5, would stop the trainig phase if the validation loss did not improve for 5 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj1HtnQYdQqp"
      },
      "source": [
        "lr = 1e-5 #@param {type:\"number\"}\n",
        "betas = (0.99, 0.999) \n",
        "batch_size = 4 #@param {type:\"number\"}\n",
        "epochs = 1000 #@param {type:\"number\"}\n",
        "early_stopping = np.min((int(epochs/5), 15))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVLo2infdRNX"
      },
      "source": [
        "##**Training Phase**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0OJ-NejdVa5"
      },
      "source": [
        "if(TrainNet):\n",
        "    model = CustomNet(torch.numel(X_train[0]), [128, 128, 128, 128])\n",
        "    \n",
        "    criterion = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
        "\n",
        "    dl_train = CreateDataLoader(X_train, y_train, batch_size=batch_size)\n",
        "    dl_val = CreateDataLoader(X_val, y_val, batch_size=1)\n",
        "\n",
        "    # ================= Train Net ================\n",
        "    trainer = Trainer(model, criterion, optimizer)\n",
        "    trainer.fit(dl_train, dl_val, num_epochs=epochs, early_stopping=early_stopping, print_every=1)\n",
        "    torch.save(trainer.model.state_dict(), 'model_final_gauss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysUduqPldV_N"
      },
      "source": [
        "##**Load Pre-trained Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eiu6XAGuda6Y"
      },
      "source": [
        "model = CustomNet(torch.numel(X_train[0]), [128, 128, 128, 128])\n",
        "model.load_state_dict(torch.load(preTrainedModel))\n",
        "print(\"Pretrained model loaded successfully\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T_I8F7wdbQm"
      },
      "source": [
        "##**Testing Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH6fvucpdeMm"
      },
      "source": [
        "y_val_pred = model(X_val)\n",
        "y_test_pred = model(X_test).squeeze()\n",
        "y_test_pred = torch.max(y_test_pred, torch.zeros(y_test_pred.shape))\n",
        "\n",
        "val_acc = torch.mean(torch.abs(y_val_pred.squeeze() - y_val))\n",
        "print(\"Neural Network Validation MSE:\", 100 * val_acc.item())\n",
        "\n",
        "print(\"Printing dimer percentage per experiment:\")\n",
        "if(y_test_pred.shape == torch.Size([])):\n",
        "    print(\"1: \", 100 * y_test_pred.item())\n",
        "else:\n",
        "    for i in range(y_test_pred.shape[0]):\n",
        "        print(str(i+1)+\": \", 100 * y_test_pred[i].item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW4uD8ELdgF-"
      },
      "source": [
        "##**Detection Efficiency Correction**\n",
        "Please specify the detection efficiency in your experiment. It should be a number in the range [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwMcuVm1dlYH"
      },
      "source": [
        "detection_efficiency = 0.78 #@param {type:\"number\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "511x4mzidloI"
      },
      "source": [
        "###**Calculate Final Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obenZhW1dlt0"
      },
      "source": [
        "print(\"Printing corrected dimer percentage per experiment:\")\n",
        "if(y_test_pred.shape == torch.Size([])):\n",
        "    print(\"1: \", 100 * find_actual_dimers_percentage(y_test_pred.item(), detection_efficiency))\n",
        "else:\n",
        "    for i in range(y_test_pred.shape[0]):\n",
        "         print(str(i+1)+\": \", 100 * find_actual_dimers_percentage(y_test_pred[i].item(), detection_efficiency))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}